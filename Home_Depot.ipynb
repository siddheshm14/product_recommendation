{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Home_Depot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtIypJKpg0D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4c4946-68f9-48a9-93fc-4572c32d0d84"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.neighbors import NearestNeighbors\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.metrics import adjusted_rand_score\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "!pip install scikit-learn==0.23.2"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (1.19.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVfn8s_QjJWH",
        "outputId": "e0e64385-23d9-47d5-bcf4-818cf85e4786"
      },
      "source": [
        "product_des=pd.read_csv('/content/drive/MyDrive/Home_depot_relevance_search/product_descriptions.csv')\r\n",
        "product_des.shape\r\n",
        "\r\n",
        "\r\n",
        "product_des.isnull().sum()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "product_uid            0\n",
              "product_description    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GU5SLNsTj6Wa",
        "outputId": "3573bb29-0e32-4e6f-e675-6556f5d51104"
      },
      "source": [
        "\r\n",
        "product_des.shape\r\n",
        "product_des.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001</td>\n",
              "      <td>Not only do angles make joints stronger, they ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100002</td>\n",
              "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100003</td>\n",
              "      <td>Classic architecture meets contemporary design...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100004</td>\n",
              "      <td>The Grape Solar 265-Watt Polycrystalline PV So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100005</td>\n",
              "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_uid                                product_description\n",
              "0       100001  Not only do angles make joints stronger, they ...\n",
              "1       100002  BEHR Premium Textured DECKOVER is an innovativ...\n",
              "2       100003  Classic architecture meets contemporary design...\n",
              "3       100004  The Grape Solar 265-Watt Polycrystalline PV So...\n",
              "4       100005  Update your bathroom with the Delta Vero Singl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DcKCMrPkgtt",
        "outputId": "82d65943-408b-4b02-d552-409735e4b41d"
      },
      "source": [
        "product_des1=product_des.head(10000)\r\n",
        "product_des1.shape\r\n",
        "import sklearn\r\n",
        "print('sklearn',sklearn.__version__)\r\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sklearn 0.23.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbVnBL6rLx7r",
        "outputId": "34714dfc-0b12-4637-9f8e-d946188945f6"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('stopwords')\r\n",
        "import re\r\n",
        "import string\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "lemmatizer=WordNetLemmatizer()\r\n",
        "stopwords=nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcLXzSiKOXlz"
      },
      "source": [
        "def clean_text(txt):\r\n",
        "  txt=\"\".join([c for c in txt if c not in string.punctuation])\r\n",
        "  tokens=re.split('\\W+',txt)\r\n",
        "  txt=[word for word in tokens if word not in stopwords]\r\n",
        "  txt=[lemmatizer.lemmatize(word) for word in txt if word not in stopwords]\r\n",
        "  return txt"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW-ASwbwPKh2"
      },
      "source": [
        "product_des1['product_description_2']=product_des1['product_description'].apply(lambda x:clean_text(x))\r\n",
        "product_des1.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh8QevuwJEcO"
      },
      "source": [
        "def lemmatization(input_text):\r\n",
        "  text=[lemmatizer.lemmatize(word)for word in input_text if word not in stopwords]\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7W3wZwJLJ7A"
      },
      "source": [
        "product_des1['product_description_2']=product_des1['product_description_2'].apply(lambda x:lemmatization(x))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0SojlPKMZsB"
      },
      "source": [
        "data=product_des1['product_description_2']\r\n",
        "corpus=[]\r\n",
        "for line in data:\r\n",
        "  description=' '.join(line)\r\n",
        "  description=description.lower()\r\n",
        "  corpus.append(description)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdIyC7w1oydX"
      },
      "source": [
        "#Writing corpus.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT7dBta7o24y"
      },
      "source": [
        "with open('corpus.txt', 'w') as filehandle:\r\n",
        "    for listitem in corpus:\r\n",
        "        filehandle.write('%s\\n' % listitem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB1aLK3do7k-"
      },
      "source": [
        "#Reading corpus.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEE6BK188YQR"
      },
      "source": [
        "corpus_data = []\r\n",
        "\r\n",
        "# open file and read the content in a list\r\n",
        "with open('corpus.txt', 'r') as filehandle:\r\n",
        "    for line in filehandle:\r\n",
        "        # remove linebreak which is the last character of the string\r\n",
        "        currentPlace = line[:-1]\r\n",
        "\r\n",
        "        # add item to the list\r\n",
        "        corpus_data.append(line)\r\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV3LbIyhPO5O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEemCHU_nbL2"
      },
      "source": [
        "#Feature extraction from product Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzyeCfTQnfW2"
      },
      "source": [
        "vectorizer=TfidfVectorizer(stop_words='english',analyzer='word',max_features=500)\r\n",
        "\r\n",
        "\r\n",
        "#X=vectorizer.fit_transform(converted_list)\r\n",
        "X=vectorizer.fit_transform(corpus_data)\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd4oQ11upV4R"
      },
      "source": [
        "#Visualizing Clusters in subset of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjufF8kYpbRm"
      },
      "source": [
        "#from sklearn.cluster import KMeans\r\n",
        "#within_cluster_sum_of_sqr=[]\r\n",
        "\r\n",
        "#for i in range(1,11):\r\n",
        "  #km=KMeans(n_clusters=i,\r\n",
        "#            init='k-means++',\r\n",
        "#            max_iter=300,\r\n",
        "#            n_init=10,\r\n",
        "#            random_state=0,\r\n",
        "#            algorithm='full',\r\n",
        "#            tol=0.001)\r\n",
        "#  km.fit(X)\r\n",
        "#  labels=km.labels_\r\n",
        "#  within_cluster_sum_of_sqr.append(km.inertia_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HnGLUigsYRU"
      },
      "source": [
        "#plt.rcParams['figure.figsize']=(13,6)\r\n",
        "#plt.plot(range(1,11),within_cluster_sum_of_sqr)\r\n",
        "#plt.grid()\r\n",
        "#plt.tight_layout()\r\n",
        "#plt.title('The Elbow Method')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbeQBMQQAJbR"
      },
      "source": [
        "#kmeans=KMeans(n_clusters=10,init='k-means++')\r\n",
        "#y_kmeans=kmeans.fit_predict(X)\r\n",
        "#plt.plot(y_kmeans,\".\")\r\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYCtO7KBFB6O"
      },
      "source": [
        "def print_cluster(i):\r\n",
        "  cluster_list=[]\r\n",
        "  cluster_list.clear()\r\n",
        "  print(\"Cluster %d:\" % i)\r\n",
        "  for ind in ordered_centroids[i, :10]:\r\n",
        "    print(' %s' % terms[ind])\r\n",
        "    cluster_list.append(terms[ind])\r\n",
        "\r\n",
        "  return cluster_list\r\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY_2qmmvCm2s"
      },
      "source": [
        "k_value=10\r\n",
        "\r\n",
        "model=KMeans(n_clusters=k_value ,\r\n",
        "             init='k-means++',\r\n",
        "             max_iter=300,\r\n",
        "             n_init=10,\r\n",
        "             random_state=0,\r\n",
        "             algorithm='full',\r\n",
        "            tol=0.001\r\n",
        "             )\r\n",
        "             \r\n",
        "model.fit(X)\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdKnaB29imCt"
      },
      "source": [
        "print(\"Top search per clusters :\")\r\n",
        "ordered_centroids=model.cluster_centers_.argsort()[:,::-1]\r\n",
        "terms=vectorizer.get_feature_names()\r\n",
        "for i in range(k_value):\r\n",
        "  print_cluster(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXEDlrv8jxVv"
      },
      "source": [
        "ordered_centroids.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q16DwI45M3Fy"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "pickle.dump(model,open('Kmeans_cluster.pkl','wb'))\r\n",
        "pickle.load(open('Kmeans_cluster.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op4PicaAVnd_"
      },
      "source": [
        "model1=pickle.load(open('Kmeans_cluster.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvEcmYwIHtPd"
      },
      "source": [
        "def selected_cluster(i):\r\n",
        "  cluster=[]\r\n",
        "  cluster.clear()\r\n",
        "  print(\"Cluster %d:\" % i)\r\n",
        "  for ind in ordered_centroids[i, :10]:\r\n",
        "    print(' %s' % terms[ind])\r\n",
        "    cluster.append(terms[ind])\r\n",
        "  return cluster\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9DN2F0NIW3D"
      },
      "source": [
        "def show_recommendations(product):\r\n",
        "  Y=vectorizer.transform([product])\r\n",
        "  prediction=model1.predict(Y)\r\n",
        "  cluster=selected_cluster(prediction[0])\r\n",
        "  return cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_roggzpfJYzW"
      },
      "source": [
        "domain=show_recommendations(\"cutting tool\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsfI9i7CMQoV"
      },
      "source": [
        "domain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj9YIG0cYoTC"
      },
      "source": [
        "#joined_df= pd.read_csv('/content/drive/MyDrive/Home_depot_relevance_search/joined_prod_title_and_Prod_des.csv',\r\n",
        "                       #encoding= 'unicode_escape')\r\n",
        "\r\n",
        "#joined_df= pd.read_csv('https://drive.google.com/file/d/1ayy2Qr-DzdHZrmKKm4PC-iQ0CcmLaQ54/view?usp=sharing',\r\n",
        "                       #encoding= 'unicode_escape')\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "url = 'https://drive.google.com/file/d/1ayy2Qr-DzdHZrmKKm4PC-iQ0CcmLaQ54/view?usp=sharing'\r\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\r\n",
        "joined_df = pd.read_csv(path,encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdhnSdmIfhiR"
      },
      "source": [
        "joined_df=joined_df.dropna()\r\n",
        "joined_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fadjydVOiXzc"
      },
      "source": [
        "new_df=joined_df[joined_df['product_title'].str.contains('lithium-ion',regex=False,case=False,na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CDUo5gBk-jZ"
      },
      "source": [
        "products=new_df['product_title'].unique()\r\n",
        "print(products[:10])\r\n",
        "products=pd.DataFrame(products)\r\n",
        "products.head(10)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYpDtd0bN_1"
      },
      "source": [
        "df=pd.DataFrame(products[:10])\r\n",
        "df.rename({0:\"Featuring top 10 Products\"},axis=1,inplace=True)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoQmeYsLtNPF"
      },
      "source": [
        "#from sklearn.metrics import silhouette_score\r\n",
        "#for n_clusters in range(2,11):\r\n",
        "    #clusterer = KMeans(n_clusters=n_clusters)\r\n",
        "    #preds = clusterer.fit_predict(X)\r\n",
        "    #centers = clusterer.cluster_centers_\r\n",
        "\r\n",
        "    #score = silhouette_score(X, preds)\r\n",
        "    #print(\"For n_clusters = {}, silhouette score is {})\".format(n_clusters, score))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}